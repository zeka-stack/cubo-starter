<!-- 将日志输出到指定位置的文件中 -->
<RollingRandomAccessFile name="ALL_FILE"
                         fileName="${LOG_BASE_FOLDER}/${sys:LOG_FILE}"
                         filePattern="${LOG_BASE_FOLDER}/%d{yyyy-MM-dd}/${sys:LOG_FILE}-${sys:ROLLING_FILE_NAME_PATTERN}"
                         immediateFlush="false">
    <!-- 日志输出格式 -->
    <PatternLayout charset="${LOG_CHARSET}">
        <MarkerPatternSelector defaultPattern="${sys:FILE_LOG_PATTERN}">
            <PatternMatch key="banner" pattern="${MARKER_PATTERN}"/>
            <PatternMatch key="properties" pattern="${MARKER_PATTERN}"/>
            <PatternMatch key="processor" pattern="${MARKER_PATTERN}"/>
            <PatternMatch key="tracer" pattern="${sys:TRACER_MARKER_PATTERN}"/>
        </MarkerPatternSelector>
    </PatternLayout>
    <!-- interval单位为filePattern最后一个单位, 此处单位为小时, modulate若为true,
        则日志时间将以0点为边界进行偏移计算, 由于加了.gz策略, 所以此处意思为每隔1小时, 便会新生成一个
        log4j2的压缩文件, 当每个文件超过 LOG_FILE_MAX_SIZE 时, 也会新生成一个log4j2的压缩文件 -->
    <Policies>
        <TimeBasedTriggeringPolicy modulate="true" interval="1"/>
        <SizeBaseDTriggeringPolicy size="${LOG_FILE_MAX_SIZE}"/>
    </Policies>
    <Filters>
        <!-- 写入 INFO 及以上的日志 -->
        <ThresholdFilter level="INFO" onMatch="ACCEPT" onMismatch="DENY"/>
    </Filters>

    <!-- 最多备份30天以内||日志文件大小达到100GB的日志||文件数量超过十个
    此处为策略限制, Delete中可以按自己需要用正则表达式编写 -->
    <DefaultRolloverStrategy max="${LOG_FILE_TOTAL_SIZE_CAP}">
        <Delete basePath="${LOG_BASE_FOLDER}" maxDepth="2">
            <IfFileName glob="*/${sys:LOG_FILE}-*.log.gz"/>
            <IfLastModified age="${LOG_FILE_MAX_HISTORY}d"/>
        </Delete>
    </DefaultRolloverStrategy>
</RollingRandomAccessFile>
